{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying Fraud from Enron Data\n",
    "### - Marty VanHoof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Founded in 1985, Enron was one of the world's major electricity, natural gas, communications and pulp and paper companies.  Enron was named \"America's Most Innovative Company\" for six consecutive years by *Fortune* magazine.  Much of this apparent success, though, was due to systematic and elaborate accounting fraud and corruption.  By the use of accounting loopholes, special purpose entities, and poor financial reporting, they were able to hide billions of dollars in debt from failed deals and projects.  By 2002, it had collapsed into bankruptcy, and many executives at Enron would later be indicted and some of them sent to prison.  In the resulting investigation, a large amount of typically confidential information entered into the public record.  This included a large database of emails known as the *Enron Corpus*, and also detailed financial data for top executives.  \n",
    "\n",
    "The purpose of this project is to try to probe this financial and email data using machine learning techniques in order to attempt to identify persons of interest (POI) in the Enron scandal.  POIs are individuals who were indicted, reached a settlement or plea deal with the government, or testified in exchange for prosecution immunity.  This report details the following process:\n",
    "* [Data Exploration and Outlier Removal](#exploration)\n",
    "* [Initial Classifier Estimation](#initial)\n",
    "* [Feature Engineering](#engineering)\n",
    "* [Feature Selection](#selection)\n",
    "* [Algorithm Tuning](#tuning)\n",
    "* [1. Naive Bayes ](#gnb)\n",
    "    * [1a. Tuning Naive Bayes](#tuning_gnb)\n",
    "    * [1b. Naive Bayes Results](#nb_results)\n",
    "* [2. Decision Tree Classifier](#dt)\n",
    "    * [2a. Tuning the Decision Tree](#tuning_dt)\n",
    "    * [2b. Decision Tree Results](#dt_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exploration'></a>\n",
    "## Data Exploration / Outlier Removal\n",
    "\n",
    "We begin by doing some exploratory data analysis (EDA) in order to get a better understanding of the dataset and remove a few outliers.  The Enron email and financial data has been preprocessed and combined into a Python dictionary, where each key-value pair in the dictionary corresponds to one person.  The dictionary key is the person's name, and the value is another dictionary, which contains the names of all the features and their values for that person. \n",
    "\n",
    "In order to make our EDA easier, we will use the Python library Pandas to first transform our Python dictionary into a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# load the dictionary containing the dataset\n",
    "with open('enron_dataset.pkl', 'rb') as data_file:\n",
    "    data_dict = pickle.load(data_file)\n",
    "    \n",
    "# create a dataframe from data_dict and set the index column to employees\n",
    "df = pd.DataFrame.from_dict(data_dict, orient='index')\n",
    "\n",
    "# coerce numeric values into floats and convert NaN values to 0\n",
    "df = df.apply(lambda x: pd.to_numeric(x, errors='coerce'))\n",
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the first 5 rows of our dataset.  The row observations correspond to Enron employees and the columns are the features (the email and financial information for the employee).  There were many missing values in the original financial dataset and these values were encoded in the Python dictionary as 'NaN'.  These NaN values are transformed to 0 in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>bonus</th>\n",
       "      <th>email_address</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>...</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>other</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>poi</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>director_fees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ALLEN PHILLIP K</th>\n",
       "      <td>201955.0</td>\n",
       "      <td>2902.0</td>\n",
       "      <td>2869717.0</td>\n",
       "      <td>4484442.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4175000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-126027.0</td>\n",
       "      <td>-3081055.0</td>\n",
       "      <td>1729541.0</td>\n",
       "      <td>...</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1729541.0</td>\n",
       "      <td>2195.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>False</td>\n",
       "      <td>304805.0</td>\n",
       "      <td>1407.0</td>\n",
       "      <td>126027.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BADUM JAMES P</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>178980.0</td>\n",
       "      <td>182466.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>257817.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>257817.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BANNANTINE JAMES M</th>\n",
       "      <td>477.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>916197.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-560222.0</td>\n",
       "      <td>-5104.0</td>\n",
       "      <td>5243487.0</td>\n",
       "      <td>...</td>\n",
       "      <td>39.0</td>\n",
       "      <td>4046157.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>864523.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>465.0</td>\n",
       "      <td>1757552.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAXTER JOHN C</th>\n",
       "      <td>267102.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1295738.0</td>\n",
       "      <td>5634343.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1200000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1386055.0</td>\n",
       "      <td>10623258.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6680544.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2660303.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1586055.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3942714.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAY FRANKLIN R</th>\n",
       "      <td>239671.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>260455.0</td>\n",
       "      <td>827696.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-82782.0</td>\n",
       "      <td>-201641.0</td>\n",
       "      <td>63014.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>145796.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      salary  to_messages  deferral_payments  total_payments  \\\n",
       "ALLEN PHILLIP K     201955.0       2902.0          2869717.0       4484442.0   \n",
       "BADUM JAMES P            0.0          0.0           178980.0        182466.0   \n",
       "BANNANTINE JAMES M     477.0        566.0                0.0        916197.0   \n",
       "BAXTER JOHN C       267102.0          0.0          1295738.0       5634343.0   \n",
       "BAY FRANKLIN R      239671.0          0.0           260455.0        827696.0   \n",
       "\n",
       "                    loan_advances      bonus  email_address  \\\n",
       "ALLEN PHILLIP K               0.0  4175000.0            0.0   \n",
       "BADUM JAMES P                 0.0        0.0            0.0   \n",
       "BANNANTINE JAMES M            0.0        0.0            0.0   \n",
       "BAXTER JOHN C                 0.0  1200000.0            0.0   \n",
       "BAY FRANKLIN R                0.0   400000.0            0.0   \n",
       "\n",
       "                    restricted_stock_deferred  deferred_income  \\\n",
       "ALLEN PHILLIP K                     -126027.0       -3081055.0   \n",
       "BADUM JAMES P                             0.0              0.0   \n",
       "BANNANTINE JAMES M                  -560222.0          -5104.0   \n",
       "BAXTER JOHN C                             0.0       -1386055.0   \n",
       "BAY FRANKLIN R                       -82782.0        -201641.0   \n",
       "\n",
       "                    total_stock_value      ...        from_poi_to_this_person  \\\n",
       "ALLEN PHILLIP K             1729541.0      ...                           47.0   \n",
       "BADUM JAMES P                257817.0      ...                            0.0   \n",
       "BANNANTINE JAMES M          5243487.0      ...                           39.0   \n",
       "BAXTER JOHN C              10623258.0      ...                            0.0   \n",
       "BAY FRANKLIN R                63014.0      ...                            0.0   \n",
       "\n",
       "                    exercised_stock_options  from_messages      other  \\\n",
       "ALLEN PHILLIP K                   1729541.0         2195.0      152.0   \n",
       "BADUM JAMES P                      257817.0            0.0        0.0   \n",
       "BANNANTINE JAMES M                4046157.0           29.0   864523.0   \n",
       "BAXTER JOHN C                     6680544.0            0.0  2660303.0   \n",
       "BAY FRANKLIN R                          0.0            0.0       69.0   \n",
       "\n",
       "                    from_this_person_to_poi    poi  long_term_incentive  \\\n",
       "ALLEN PHILLIP K                        65.0  False             304805.0   \n",
       "BADUM JAMES P                           0.0  False                  0.0   \n",
       "BANNANTINE JAMES M                      0.0  False                  0.0   \n",
       "BAXTER JOHN C                           0.0  False            1586055.0   \n",
       "BAY FRANKLIN R                          0.0  False                  0.0   \n",
       "\n",
       "                    shared_receipt_with_poi  restricted_stock  director_fees  \n",
       "ALLEN PHILLIP K                      1407.0          126027.0            0.0  \n",
       "BADUM JAMES P                           0.0               0.0            0.0  \n",
       "BANNANTINE JAMES M                    465.0         1757552.0            0.0  \n",
       "BAXTER JOHN C                           0.0         3942714.0            0.0  \n",
       "BAY FRANKLIN R                          0.0          145796.0            0.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Dataset Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of data points:  146\n",
      "number of features:  21\n",
      "number of POIs:  18\n",
      "number of non POIs:  128\n"
     ]
    }
   ],
   "source": [
    "print('number of data points: ', df.shape[0])\n",
    "print('number of features: ', df.shape[1])\n",
    "print('number of POIs: ', df.query('poi == True').shape[0])\n",
    "print('number of non POIs: ', df.query('poi == False').shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the features with missing values (zeros) and the number of missing values for each feature.  We exclude the email addresses since they don't provide useful information and were all converted to zeros in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "salary                        51\n",
       "to_messages                   60\n",
       "deferral_payments            107\n",
       "total_payments                21\n",
       "loan_advances                142\n",
       "bonus                         64\n",
       "restricted_stock_deferred    128\n",
       "deferred_income               97\n",
       "total_stock_value             20\n",
       "expenses                      51\n",
       "from_poi_to_this_person       72\n",
       "exercised_stock_options       44\n",
       "from_messages                 60\n",
       "other                         53\n",
       "from_this_person_to_poi       80\n",
       "poi                          128\n",
       "long_term_incentive           80\n",
       "shared_receipt_with_poi       60\n",
       "restricted_stock              36\n",
       "director_fees                129\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the number of missing values (zeros) for each feature except 'email_address'\n",
    "zero_counts = (~df.astype(bool)).sum(axis=0)\n",
    "zero_counts.drop('email_address')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers\n",
    "\n",
    "Now we will remove a few outliers from the dataset.  Since the dataset is quite small, we should be conservative in removing outliers.  Also, due to the nature of the financial data, outliers such as very larges salaries, bonuses, etc, can be a signal that a particular individual is a POI, so we won't remove any of these (except for the 'TOTAL' row mentioned next). \n",
    "\n",
    "Statistically, an outlier is defined to be an observation that is below the first quartile $Q_1$ or above the third quartile $Q_3$ by more than 1.5 times the *interquartile range*, which is $Q_3 - Q_1$.  More specifically, let \n",
    "\n",
    "$$ IQR = Q_3 - Q_1 $$\n",
    "\n",
    "be the interquartile range.  Then any data point $x$ for which\n",
    "\n",
    "$$ x \\leq Q_1 - 1.5 \\cdot IQR \\quad \\textrm{or} \\quad x \\geq Q_3 + 1.5 \\cdot IQR $$\n",
    "\n",
    "can be considered an outlier.  As mentioned above, outliers of this sort can be indicative of persons of interest so we should be very careful about removing them.  In the code below, we will only look for outliers in the upper range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlier_count</th>\n",
       "      <th>poi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LAY KENNETH L</th>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FREVERT MARK A</th>\n",
       "      <td>14</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WHALLEY LAWRENCE G</th>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SKILLING JEFFREY K</th>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOTAL</th>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DELAINEY DAVID W</th>\n",
       "      <td>12</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAVORATO JOHN J</th>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    outlier_count    poi\n",
       "LAY KENNETH L                  15   True\n",
       "FREVERT MARK A                 14  False\n",
       "WHALLEY LAWRENCE G             13  False\n",
       "SKILLING JEFFREY K             13   True\n",
       "TOTAL                          12  False\n",
       "DELAINEY DAVID W               12   True\n",
       "LAVORATO JOHN J                10  False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# find the individuals with 10 or more outlier features in the upper range\n",
    "Q1, Q3 = df.quantile(0.25), df.quantile(0.75) \n",
    "IQR = Q3 - Q1\n",
    "outliers = df[df > Q1 + 1.5*IQR]\n",
    "outlier_counts = outliers.count(axis=1).sort_values(ascending=False).head(7)\n",
    "outlier_counts = outlier_counts.to_frame(name='outlier_count')\n",
    "names = list(outlier_counts.index)\n",
    "outlier_counts['poi'] = df.loc[names].poi\n",
    "display(outlier_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this information, we will remove Mark Frevert, Lawrence Whalley, and John Lavorato.  These people are not persons of interest even though they seem to have an unusually high number of outlier features.  \n",
    "\n",
    "The TOTAL row is also an anomaly.  The Enron financial data comes from a PDF file called [enron61702insiderpay.pdf](enron61702insiderpay.pdf), which contains a row of totals for each financial feature, and this row was read into the Python dictionary (and thus in the dataframe) as an individual observation where it really doesn't belong.  We can get a good view of this outlier from a scatterplot of salaries and bonuses of Enron employees.  This outlier should really be removed because it will throw off our predictions when we try to fit models to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114cff390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.plot.scatter(x='salary', y='bonus', color='blue',\n",
    "                title='Plot of Salary and Bonus (with outlier)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rows containing all zeros\n",
    "\n",
    "We should also check for observations that contain all zeros, and we can see that this person 'LOCKHART EUGENE E' doesn't have any records.  Finally, if we examine all the names in the dataframe there is one that doesn't seem to belong:  'THE TRAVEL AGENCY IN THE PARK'.  This is probably not a person, so we will remove this observation as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>bonus</th>\n",
       "      <th>email_address</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>...</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>other</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>poi</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>director_fees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LOCKHART EUGENE E</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   salary  to_messages  deferral_payments  total_payments  \\\n",
       "LOCKHART EUGENE E     0.0          0.0                0.0             0.0   \n",
       "\n",
       "                   loan_advances  bonus  email_address  \\\n",
       "LOCKHART EUGENE E            0.0    0.0            0.0   \n",
       "\n",
       "                   restricted_stock_deferred  deferred_income  \\\n",
       "LOCKHART EUGENE E                        0.0              0.0   \n",
       "\n",
       "                   total_stock_value      ...        from_poi_to_this_person  \\\n",
       "LOCKHART EUGENE E                0.0      ...                            0.0   \n",
       "\n",
       "                   exercised_stock_options  from_messages  other  \\\n",
       "LOCKHART EUGENE E                      0.0            0.0    0.0   \n",
       "\n",
       "                   from_this_person_to_poi    poi  long_term_incentive  \\\n",
       "LOCKHART EUGENE E                      0.0  False                  0.0   \n",
       "\n",
       "                   shared_receipt_with_poi  restricted_stock  director_fees  \n",
       "LOCKHART EUGENE E                      0.0               0.0            0.0  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>bonus</th>\n",
       "      <th>email_address</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>...</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>other</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>poi</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>director_fees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>THE TRAVEL AGENCY IN THE PARK</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>362096.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>362096.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               salary  to_messages  deferral_payments  \\\n",
       "THE TRAVEL AGENCY IN THE PARK     0.0          0.0                0.0   \n",
       "\n",
       "                               total_payments  loan_advances  bonus  \\\n",
       "THE TRAVEL AGENCY IN THE PARK        362096.0            0.0    0.0   \n",
       "\n",
       "                               email_address  restricted_stock_deferred  \\\n",
       "THE TRAVEL AGENCY IN THE PARK            0.0                        0.0   \n",
       "\n",
       "                               deferred_income  total_stock_value  \\\n",
       "THE TRAVEL AGENCY IN THE PARK              0.0                0.0   \n",
       "\n",
       "                                   ...        from_poi_to_this_person  \\\n",
       "THE TRAVEL AGENCY IN THE PARK      ...                            0.0   \n",
       "\n",
       "                               exercised_stock_options  from_messages  \\\n",
       "THE TRAVEL AGENCY IN THE PARK                      0.0            0.0   \n",
       "\n",
       "                                  other  from_this_person_to_poi    poi  \\\n",
       "THE TRAVEL AGENCY IN THE PARK  362096.0                      0.0  False   \n",
       "\n",
       "                               long_term_incentive  shared_receipt_with_poi  \\\n",
       "THE TRAVEL AGENCY IN THE PARK                  0.0                      0.0   \n",
       "\n",
       "                               restricted_stock  director_fees  \n",
       "THE TRAVEL AGENCY IN THE PARK               0.0            0.0  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(df.loc[(df == 0).all(axis=1)])\n",
    "df[df.index.values == 'THE TRAVEL AGENCY IN THE PARK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove outliers\n",
    "to_remove = ['FREVERT MARK A', 'LAVORATO JOHN J', 'WHALLEY LAWRENCE G',\n",
    "             'TOTAL', 'LOCKHART EUGENE E', 'THE TRAVEL AGENCY IN THE PARK']  \n",
    "df.drop(to_remove, inplace=True)\n",
    "    \n",
    "while False:\n",
    "    to_remove = ['FREVERT MARK A', 'BAXTER JOHN C', 'LAVORATO JOHN J',\n",
    "                 'WHALLEY LAWRENCE G', 'TOTAL', 'LOCKHART EUGENE E',\n",
    "                 'THE TRAVEL AGENCY IN THE PARK']\n",
    "    df.drop(to_remove, inplace=True)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='initial'></a>\n",
    "## Initial Classifier Estimation\n",
    "\n",
    "We will start by experimenting with a few different classifiers without worrying about parameter-tuning at this point.  Using the **`test_classifier()`** function in the [tester.py](tester.py) file, we can get an initial idea of the performance of each classifier before we get into tuning the parameters.  We will start by using all the features in the dataset (except email address).  The metrics that we want to optimize are the precision, recall, and the F1 score.\n",
    "\n",
    "Consider the collection of all people in the Enron dataset who the model predicts to be a POI; then the **precision** is the proportion of those people who are actually POIs.  More precisely, if $TP$ is the number of true positives and $FP$ is the number of false positives, then\n",
    "\n",
    "$$\n",
    "\\textrm{precision} = \\frac{TP}{TP + FP}\n",
    "$$\n",
    "\n",
    "Now consider the collection of all people in the Enron dataset who are actually POIs; then the **recall** is the proportion of those individuals who are predicted by the model to be POIs.  If $FN$ is the number of false negatives, then\n",
    "\n",
    "$$\n",
    "\\textrm{recall} = \\frac{TP}{TP + FN}\n",
    "$$\n",
    "\n",
    "The **F1 score** is the harmonic mean of precision and recall and can also be interpreted as a weighted average of precision and recall\n",
    "\n",
    "$$\n",
    "\\textrm{F1 score} = \\frac{2}{\\frac{1}{\\textrm{precision}} + \\frac{1}{\\textrm{recall}}} = \\frac{2 \\cdot \\textrm{precision} \\cdot \\textrm{recall}}{\\textrm{precision} + \\textrm{recall}}\n",
    "$$\n",
    "\n",
    "Note that our dataset is imbalanced, since there are 18 POI versus 128 non POI.  This means that the accuracy score (number of accurate predictions divided by the total number of data points) is not a good metric to use.\n",
    "\n",
    "At this point we should also standardize the data since the financial and email data are measured in different units and on different scales.  We will standardize the data so that it has mean 0 and standard deviation 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tester import test_classifier\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "# convert the dataframe back into a dictionary\n",
    "data_dict = df.to_dict('index')\n",
    "\n",
    "# get a list of all the features and remove 'email_address'\n",
    "features_list = list(df.columns.values)\n",
    "features_list.remove('email_address')\n",
    "\n",
    "# move 'poi' to the beginning of the list for use by the function\n",
    "# targetFeatureSplit() in feature_format.py\n",
    "features_list.pop(features_list.index('poi'))\n",
    "features_list.insert(0, 'poi')\n",
    "\n",
    "def clf_report(classifier, f_list, d_dict):\n",
    "    ''' \n",
    "    A quick and dirty function that fits a specific classifier then uses 'test_classifier()'\n",
    "    to evaluate the model's performance \n",
    "        \n",
    "    Inputs:\n",
    "    classifier - An sklearn classifier with the default hyperparameters\n",
    "    f_list - A list of features to use\n",
    "    d_dict - A data dictionary where each key-value pair corresponds to one individual\n",
    "    '''\n",
    "    \n",
    "    # Extract features and labels from data_dict\n",
    "    data_array = featureFormat(d_dict, f_list, sort_keys = True)\n",
    "    labels, features = targetFeatureSplit(data_array)\n",
    "    \n",
    "    # Apply feature scaling\n",
    "    features = scale(features)\n",
    "\n",
    "    # Split features and labels into training and testing sets\n",
    "    features_train, features_test, labels_train, labels_test = \\\n",
    "        train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "    \n",
    "    clf = classifier()\n",
    "    clf.fit(features_train, labels_train)\n",
    "    test_classifier(clf, d_dict, f_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75721\tPrecision: 0.25186\tRecall: 0.35500\tF1: 0.29467\tF2: 0.32813\n",
      "Total predictions: 14000\tTrue positives:  710\tFalse positives: 2109\n",
      "False negatives: 1290\tTrue negatives: 9891\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_report(GaussianNB, features_list, data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.82243\tPrecision: 0.36002\tRecall: 0.31250\tF1: 0.33458\tF2: 0.32097\n",
      "Total predictions: 14000\tTrue positives:  625\tFalse positives: 1111\n",
      "False negatives: 1375\tTrue negatives: 10889\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_report(DecisionTreeClassifier, features_list, data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.78636\tPrecision: 0.21572\tRecall: 0.18800\tF1: 0.20091\tF2: 0.19296\n",
      "Total predictions: 14000\tTrue positives:  376\tFalse positives: 1367\n",
      "False negatives: 1624\tTrue negatives: 10633\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_report(LogisticRegression, features_list, data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.87693\tPrecision: 0.70102\tRecall: 0.24150\tF1: 0.35924\tF2: 0.27794\n",
      "Total predictions: 14000\tTrue positives:  483\tFalse positives:  206\n",
      "False negatives: 1517\tTrue negatives: 11794\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_report(KNeighborsClassifier, features_list, data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='engineering'></a>\n",
    "## Feature Engineering\n",
    "\n",
    "The first two features we will create are called **fraction_of_emails_to_poi** and **fraction_of_emails_from_poi**.  The hypothesis here is that persons of interest may have stronger email connections between each other, ie. that POIs send emails to other POIs at a higher rate than for the general population.  The feature **fraction_of_emails_to_poi** is the proportion of all messages from a particular person that are sent to a POI, and the feature **fraction_of_emails_from_poi** is the proportion of all messages to a particular person that are sent from a POI.\n",
    "\n",
    "If we plot the features with POI in red and non POI in blue, then there appears to be some clustering in the POIs.  Specifically, if the proportion of an individual's emails from/to a POI are below a certain threshold, then we can be confident that this individual is not a POI (the converse is not true, however).  This suggests that the above hypothesis has some merit, and we will see that these two new features will improve algorithm performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+bkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a34c5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create the two new features mentioned above\n",
    "df['fraction_of_emails_to_poi'] = (df.from_this_person_to_poi / df.from_messages).fillna(0)\n",
    "df['fraction_of_emails_from_poi'] = (df.from_poi_to_this_person / df.to_messages).fillna(0)\n",
    "\n",
    "# split the data into poi and non-poi\n",
    "df_poi = df.query('poi == True')\n",
    "df_nonpoi = df.query('poi == False')\n",
    "\n",
    "# plot the new features\n",
    "plt.scatter(df_poi.fraction_of_emails_from_poi, df_poi.fraction_of_emails_to_poi,\n",
    "            color='red', label='poi')\n",
    "plt.scatter(df_nonpoi.fraction_of_emails_from_poi, df_nonpoi.fraction_of_emails_to_poi,\n",
    "            color='blue', label='non-poi')\n",
    "plt.xlabel('fraction of emails from poi')\n",
    "plt.ylabel('fraction of emails to poi')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some more features we create are:\n",
    "- **fraction_to_from_shared_with_poi**.  The idea here is that the 2 new features above don't incorporate all the possible emails that were shared with a POI via a third party (such as cc emails). To create this new feature, we first look at the sum total of all from messages, to messages, and messages shared with a POI.  Then we take the proportion of all these messages that are either from a POI, to a POI, or shared with a POI.\n",
    "- **fraction_shared_with_poi**.\n",
    "- **bonus_to_salary** and **bonus_to_total**.  Unusually large bonuses in relation to salary and total payments could indicate fraud and might make an individual more likely to be a POI.  If we look at the mean and median of these new features grouped by non-poi/poi, there seems to be a large difference.  We could test whether these differences are statistically significant (my hunch is that they are), but a good model should detect this in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bonus_to_salary</th>\n",
       "      <th>bonus_to_total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poi</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>1.577149</td>\n",
       "      <td>0.258435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>4.776032</td>\n",
       "      <td>0.891963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bonus_to_salary  bonus_to_total\n",
       "poi                                   \n",
       "False         1.577149        0.258435\n",
       "True          4.776032        0.891963"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bonus_to_salary</th>\n",
       "      <th>bonus_to_total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poi</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.387364</td>\n",
       "      <td>0.087175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>3.862706</td>\n",
       "      <td>0.535700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bonus_to_salary  bonus_to_total\n",
       "poi                                   \n",
       "False         0.387364        0.087175\n",
       "True          3.862706        0.535700"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create the new features 'fraction_to_from_shared_with_poi', 'fraction_shared_with_poi'\n",
    "total = df.from_messages + df.to_messages + df.shared_receipt_with_poi\n",
    "to_from_shared = df.from_poi_to_this_person + df.from_this_person_to_poi +\\\n",
    "                 df.shared_receipt_with_poi\n",
    "df['fraction_to_from_shared_with_poi'] = (to_from_shared / total).fillna(0)\n",
    "df['fraction_shared_with_poi'] = (df.shared_receipt_with_poi / df.to_messages).fillna(0)\n",
    "\n",
    "# create the new features 'bonus_to_salary' and 'bonus_to_total'\n",
    "df['bonus_to_salary'] = (df.bonus / df.salary).fillna(0)\n",
    "df['bonus_to_total'] = (df.bonus / df.total_payments).fillna(0)\n",
    "\n",
    "# look at the mean and median of these new features, grouped by non-poi/poi\n",
    "display(df.groupby('poi')[['bonus_to_salary', 'bonus_to_total']].mean())\n",
    "display(df.groupby('poi')[['bonus_to_salary', 'bonus_to_total']].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# add new features to features_list\n",
    "new_features_list = features_list + ['fraction_of_emails_to_poi', 'fraction_of_emails_from_poi',\n",
    "                                     'fraction_to_from_shared_with_poi', 'bonus_to_salary',\n",
    "                                     'bonus_to_total', 'fraction_shared_with_poi']\n",
    "\n",
    "# convert df with new features back into a dictionary\n",
    "new_data_dict = df.to_dict('index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='selection'></a>\n",
    "## Feature Selection\n",
    "\n",
    "Univariate feature selection examines each feature individually to determine the strength of the relationship of each feature with the labels.  We can use sklearn's [SelectKBest](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html) algorithm along with [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) together in a [Pipeline](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) to select the best features and the optimal number of features according to a certain score.  The scoring is based on a chosen univariate statistical test; the default option is `f_classif`, which performs an Analysis of Variance (ANOVA) F-test between the labels and features.  We will stick with the default option `f_classif`.  \n",
    "\n",
    "In this project we have a binary classification problem, as we are trying to classify individuals as POI or non-POI. The scoring function `f_classif` works more generally.  Suppose we have $n$ target labels.  Then each feature can be split into $n$ groups, where observations belong to the same group if and only if they have the same class label.  The ANOVA F-test looks for a statistically significant difference among the group means by analyzing the sample variances and is based on the following:\n",
    "\n",
    "$$ \\textrm{Total Variation for each feature} = \\textrm{Variation between the groups} + \\textrm{Variation within the groups} $$\n",
    "\n",
    "The more variation there is between the groups, the more likely we are to reject the null hypothesis\n",
    "\n",
    "$$ H_0 : \\mu_1 = \\mu_2 = \\cdots = \\mu_n $$\n",
    "\n",
    "that the population means of each group are the same.  For a given feature, let $\\overline{X}_1, \\ldots, \\overline{X}_n \\,$ be the sample means for each group, and let $X_{ij}$ be the $j^{th}$ observation in group $i$.  Thus, we can write a particular group mean $\\overline{X}_i$ as\n",
    "\n",
    "$$ \n",
    "\\overline{X}_i = \\frac{1}{n_i} \\sum_{j=1}^{n_i} X_{ij} \\,, \n",
    "$$\n",
    "\n",
    "where $n_i$ is the number of observations in group $i$.  Let $\\overline{X}$ be the *grand mean*, which is the mean of all the observations of the feature in question.  The total variation is measured by the total sum of squares\n",
    "\n",
    "$$\n",
    "\\textrm{Total SS} = \\sum_{i,j} (X_{ij} - \\overline{X})^2 \\,, \n",
    "$$\n",
    "\n",
    "and Total SS is the sum of 2 parts\n",
    "\n",
    "- $SSB$ (sum of squares between groups)  \n",
    "- $SSW$ (sum of squares within groups)\n",
    "\n",
    "The $SSB$ term is given by the sum of squared deviations of each group mean from the grand mean.  Because there can be a different number of observations in each group, each squared deviation must be weighted by the group size\n",
    "\n",
    "$$\n",
    "SSB = \\sum_{i=1}^n n_i (\\overline{X}_i - \\overline{X})^2 \\,.\n",
    "$$\n",
    "\n",
    "$SSW$ is given by the sum of squared deviations of each observation from its own group mean, and is found by adding the numerators of the variances in each group.  If $s_i^2$ is the variance for group $i$, then\n",
    "\n",
    "$$ \n",
    "SSW = \\sum_{i=1}^n (n_i - 1) s_i^2 \\,.\n",
    "$$\n",
    "\n",
    "Then it can be shown that \n",
    "\n",
    "$$\n",
    "\\textrm{Total SS } = SSB + SSW \\,.  \n",
    "$$\n",
    "\n",
    "To measure the variance between the groups and the variance within the groups, we have to divide each sum of squares term by the corresponding degrees of freedom.  Let $MSB$ denote the variance between the sample means for each group, and let $MSW$ denote the variance within each group.  These are computed as follows\n",
    "\n",
    "$$\n",
    "MSB = \\frac{SSB}{n - 1} \\quad \\textrm{and} \\quad MSW = \\frac{SSW}{N - n} \\,.\n",
    "$$\n",
    "\n",
    "Here, $n$ is the number of groups and $N$ is the total number of observations.  The **F-statistic** is given by\n",
    "\n",
    "$$ F = \\frac{MSB}{MSW} \\,. $$\n",
    "\n",
    "If the variation between the sample means $(MSB)$ is significantly larger than the variation within each group $(MSW)$, then this tells us that more of the variation is due to the differences in the sample means, and makes it more likely to reject the null hypothesis\n",
    "\n",
    "$$ H_0 : \\mu_1 = \\mu_2 = \\cdots = \\mu_n $$\n",
    "\n",
    "that the population means are the same.  Hence, a large enough value of $F$ makes it more likely that there is a statistically significant difference in at least one of the population means.  \n",
    "\n",
    "This value of $F$ is the number that the `SelectKBest` algorithm uses to rank the features.  Features with a higher F value are considered ''better'' by the algorithm.  The code below uses the `SelectKBest` algorithm to get the best features along with the optimal number of features, and then displays the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_best_features(classifier, f_list, scaling=True):\n",
    "\n",
    "    num_features = np.arange(1, len(f_list))\n",
    "    data_array = featureFormat(new_data_dict, f_list, sort_keys=True)\n",
    "    labels, features = targetFeatureSplit(data_array)\n",
    "    \n",
    "    # create a pipeline with scaling/not scaling, feature selection and a classifier\n",
    "    scaler, kbest, clf = StandardScaler(), SelectKBest(), classifier()\n",
    "    if scaling:\n",
    "        steps = [('scaling', scaler), ('feature_selection', kbest), ('classifier', clf)]\n",
    "    else:\n",
    "        steps = [('feature_selection', kbest), ('classifier', clf)]\n",
    "    pipe = Pipeline(steps)\n",
    "    \n",
    "    # setup GridSearchCV with StratifiedShuffleSplit for cross validation\n",
    "    param_grid = dict(feature_selection__k = num_features)\n",
    "    cv_sss = StratifiedShuffleSplit(n_splits=100, test_size = 0.3, random_state=42)\n",
    "    grid_search = GridSearchCV(pipe, param_grid, scoring='f1', n_jobs=-1, cv=cv_sss)\n",
    "    grid_result = grid_search.fit(features, labels)\n",
    "    \n",
    "    # 'named_steps' can access the attributes/methods of a transform object in the pipeline\n",
    "    selector = grid_result.best_estimator_.named_steps['feature_selection']\n",
    "    features_selected = np.array(f_list[1:])[selector.get_support()]\n",
    "\n",
    "    return list(features_selected), grid_result.best_estimator_\n",
    "\n",
    "def display_feature_results(features_selected, estimator):\n",
    "    '''\n",
    "    Display the best features and ANOVA F-statistics in a Pandas dataframe.\n",
    "    Also test the estimator with test_classifier()\n",
    "    \n",
    "    Inputs:\n",
    "    features_selected - a list or array of features\n",
    "    estimator - best estimator from a fitted GridSearchCV object run through a pipeline\n",
    "    '''\n",
    "    # first get a list of best feature/score tuples\n",
    "    selector = estimator.named_steps['feature_selection']\n",
    "    feature_scores = selector.scores_[selector.get_support()]\n",
    "    tuples = list(zip(features_selected, feature_scores))\n",
    "    \n",
    "    # create a dataframe from feature/score tuples and display it\n",
    "    features_df = pd.DataFrame(tuples, columns=['Feature', 'F-statistic'])\n",
    "    features_df.sort_values(by=['F-statistic'], inplace=True, ascending=False)\n",
    "    features_df.reset_index(drop=True, inplace=True)\n",
    "    display(features_df)\n",
    "    \n",
    "    test_classifier(estimator, new_data_dict, ['poi']+features_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GaussianNB Best Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>F-statistic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bonus</td>\n",
       "      <td>35.578815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>exercised_stock_options</td>\n",
       "      <td>26.079999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>total_stock_value</td>\n",
       "      <td>25.714754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>salary</td>\n",
       "      <td>24.995563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bonus_to_total</td>\n",
       "      <td>20.808199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bonus_to_salary</td>\n",
       "      <td>16.562899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fraction_of_emails_to_poi</td>\n",
       "      <td>16.512128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>deferred_income</td>\n",
       "      <td>15.717961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>shared_receipt_with_poi</td>\n",
       "      <td>12.299520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>from_poi_to_this_person</td>\n",
       "      <td>11.927871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Feature  F-statistic\n",
       "0                      bonus    35.578815\n",
       "1    exercised_stock_options    26.079999\n",
       "2          total_stock_value    25.714754\n",
       "3                     salary    24.995563\n",
       "4             bonus_to_total    20.808199\n",
       "5            bonus_to_salary    16.562899\n",
       "6  fraction_of_emails_to_poi    16.512128\n",
       "7            deferred_income    15.717961\n",
       "8    shared_receipt_with_poi    12.299520\n",
       "9    from_poi_to_this_person    11.927871"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.86314\tPrecision: 0.52602\tRecall: 0.42450\tF1: 0.46984\tF2: 0.44154\n",
      "Total predictions: 14000\tTrue positives:  849\tFalse positives:  765\n",
      "False negatives: 1151\tTrue negatives: 11235\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_best_features, nb_model = get_best_features(GaussianNB, new_features_list, scaling=False)\n",
    "display_feature_results(nb_best_features, nb_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "### DecisionTreeClassifier Best Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>F-statistic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bonus</td>\n",
       "      <td>35.578815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>exercised_stock_options</td>\n",
       "      <td>26.079999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>total_stock_value</td>\n",
       "      <td>25.714754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>salary</td>\n",
       "      <td>24.995563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bonus_to_total</td>\n",
       "      <td>20.808199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bonus_to_salary</td>\n",
       "      <td>16.562899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fraction_of_emails_to_poi</td>\n",
       "      <td>16.512128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>deferred_income</td>\n",
       "      <td>15.717961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>shared_receipt_with_poi</td>\n",
       "      <td>12.299520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>from_poi_to_this_person</td>\n",
       "      <td>11.927871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>long_term_incentive</td>\n",
       "      <td>11.795978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Feature  F-statistic\n",
       "0                       bonus    35.578815\n",
       "1     exercised_stock_options    26.079999\n",
       "2           total_stock_value    25.714754\n",
       "3                      salary    24.995563\n",
       "4              bonus_to_total    20.808199\n",
       "5             bonus_to_salary    16.562899\n",
       "6   fraction_of_emails_to_poi    16.512128\n",
       "7             deferred_income    15.717961\n",
       "8     shared_receipt_with_poi    12.299520\n",
       "9     from_poi_to_this_person    11.927871\n",
       "10        long_term_incentive    11.795978"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.84429\tPrecision: 0.45268\tRecall: 0.43050\tF1: 0.44131\tF2: 0.43476\n",
      "Total predictions: 14000\tTrue positives:  861\tFalse positives: 1041\n",
      "False negatives: 1139\tTrue negatives: 10959\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Note:  in the file /Users/.../anaconda/envs/py3/lib/python3.6/site-packages/\n",
    "# sklearn/feature_selection/univariate_selection.py, I had to modify the _check_params() \n",
    "# method in SelectKBest() to avoid \"ValueError: k should be >=0, <= n_features\"\n",
    "# see https://stackoverflow.com/questions/29412348/selectkbest-based-on-estimated-amount-of-features\n",
    "dt_best_features, dt_model = get_best_features(DecisionTreeClassifier, new_features_list)\n",
    "display_feature_results(dt_best_features, dt_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression Best Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>F-statistic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bonus</td>\n",
       "      <td>35.578815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>exercised_stock_options</td>\n",
       "      <td>26.079999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>total_stock_value</td>\n",
       "      <td>25.714754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>salary</td>\n",
       "      <td>24.995563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bonus_to_total</td>\n",
       "      <td>20.808199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bonus_to_salary</td>\n",
       "      <td>16.562899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fraction_of_emails_to_poi</td>\n",
       "      <td>16.512128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Feature  F-statistic\n",
       "0                      bonus    35.578815\n",
       "1    exercised_stock_options    26.079999\n",
       "2          total_stock_value    25.714754\n",
       "3                     salary    24.995563\n",
       "4             bonus_to_total    20.808199\n",
       "5            bonus_to_salary    16.562899\n",
       "6  fraction_of_emails_to_poi    16.512128"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.84177\tPrecision: 0.47153\tRecall: 0.23600\tF1: 0.31456\tF2: 0.26219\n",
      "Total predictions: 13000\tTrue positives:  472\tFalse positives:  529\n",
      "False negatives: 1528\tTrue negatives: 10471\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lg_best_features, lg_model = get_best_features(LogisticRegression, new_features_list)\n",
    "display_feature_results(lg_best_features, lg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighborsClassifier Best Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>F-statistic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bonus</td>\n",
       "      <td>35.578815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>exercised_stock_options</td>\n",
       "      <td>26.079999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Feature  F-statistic\n",
       "0                    bonus    35.578815\n",
       "1  exercised_stock_options    26.079999"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.87500\tPrecision: 0.73901\tRecall: 0.38650\tF1: 0.50755\tF2: 0.42726\n",
      "Total predictions: 12000\tTrue positives:  773\tFalse positives:  273\n",
      "False negatives: 1227\tTrue negatives: 9727\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_best_features, knn_model = get_best_features(KNeighborsClassifier, new_features_list, scaling=False)\n",
    "display_feature_results(knn_best_features, knn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# need to add 'poi' back in because get_best_features() drops it from the list\n",
    "nb_best_features = ['poi'] + nb_best_features\n",
    "dt_best_features = ['poi'] + dt_best_features\n",
    "lg_best_features = ['poi'] + lg_best_features\n",
    "knn_best_features = ['poi'] + knn_best_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='tuning'></a>\n",
    "## Algorithm Tuning\n",
    "\n",
    "When we ran the above algorithms, we just used the default hyperparameters.  This is not a good strategy for getting an optimal model.  Most of these algorithms (except GaussianNB) have many hyperparameters that can be passed as arguments, and it is very unlikely that the default ones will produce an optimal model.  Hyperparameter-tuning involves trying different model hyperparameters and cross-validating them by training on a portion of the training set and using a holdout validation set to evaluate model performance.  Typically, a number of cross-validations are performed with different parts (called **folds**) of the training set, then a validation score is computed for each fold, and the final cross-validation score is the average of the scores for the different folds.  This process is called **k-fold cross-validation**.   \n",
    "\n",
    "Rather than using trial-and-error, we will use a more systematic method to try to optimize the hyperparameters; this involves using sklearn's Pipeline and GridSearchCV classes, as we did above when we optimized the number of features for each algorithm.  A pipeline allows us to chain transformers and estimators together so that each step is performed in sequence and we don't have to worry about keeping track of the train, validation and test data during intermediate steps. GridSearchCV is a way of systematically working through multiple combinations of hyperparameters, and cross-validating in the process, in order to find the most optimal hyperparameters in a grid that we specify.\n",
    "\n",
    "<a id='gnb'></a>\n",
    "### 1. The Naive Bayes Algorithm\n",
    "\n",
    "Naive Bayes is an algorithm used for classification problems.  Let's say we have a response variable $y$ with $k$ possible outcomes $C_1, \\ldots, C_k$.  We also have features $\\mathbf{x} = (x_1, x_2, \\dots, x_n)$ that we want to use to try to predict the outcome (class) of $y$.  We start by trying to find the conditional probability that $y$ belongs to a class $C_j$, given the features\n",
    "\n",
    "$$\n",
    "P(C_j \\,|\\, \\mathbf{x}) = P(C_j \\,|\\, x_1, x_2, \\ldots, x_n)\n",
    "$$\n",
    "\n",
    "It's natural to try to use Bayes' Theorem to compute this\n",
    "\n",
    "$$\n",
    "P(C_j \\,|\\, \\mathbf{x}) = \\frac{P(\\mathbf{x} \\,|\\, C_j) P(C_j)}{P(\\mathbf{x})} \n",
    "$$\n",
    "\n",
    "Assuming we know the values of the feature variables $x_1, \\ldots, x_n$, then the joint probability $m = P(x_1, x_2, \\ldots, x_n)$ is a constant.  So now we can write\n",
    "\n",
    "$$\n",
    "P(C_j \\,|\\, \\mathbf{x}) = \\frac{1}{m} P(\\mathbf{x} \\,|\\, C_j) P(C_j) \\quad (*)\n",
    "$$\n",
    "\n",
    "This is where the **Naive Bayes assumption** comes into play. We assume that $x_1, x_2, \\ldots, x_n$ are [conditionally independent](https://en.wikipedia.org/wiki/Conditional_independence) given $C_j \\,$:\n",
    "\n",
    "$$\n",
    "P(x_1, x_2, \\ldots, x_n \\,|\\, C_j) = P(x_1 \\,|\\, C_j) P(x_2 \\,|\\, C_j) \\cdots P(x_n \\,|\\, C_j) = \\prod_{i=1}^k P(x_i \\,|\\, C_j)\n",
    "$$\n",
    "\n",
    "This assumption is \"naive\" because in practice it is rarely true.  However, the classifier itself turns out to work well in many situations, even if the probability estimates are inaccurate.  So now $(*)$ becomes\n",
    "\n",
    "$$\n",
    "P(C_j \\,|\\, \\mathbf{x}) = \\frac{1}{m} P(C_j) \\prod_{i=1}^k P(x_i \\,|\\, C_j)   \n",
    "$$\n",
    "\n",
    "Finally, in order to make a prediction for what class the response variable $y$ belongs to, we pick the class $C_j$ that is most probable, ie.\n",
    "\n",
    "$$\n",
    "\\textrm{prediction for y} = \\underset{j \\, \\in \\{ 1, \\ldots, k \\}}{\\mathrm{argmax}} \\, P(C_j) \\prod_{i=1}^k P(x_i \\,|\\, C_j) \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tuning_gnb\"></a>\n",
    "### 1a. Tuning Naive Bayes\n",
    "\n",
    "We will start by working with the GaussianNB algorithm, as it is the most straightforward. Since GaussianNB doesn't really have any parameters to tune, we will instead try to optimize the number of principal components with principal component analysis (PCA). PCA is a way of orthogonally projecting the data to a lower dimensional space in the directions that maximize variance (or minimize information loss). Sometimes PCA will increase the performance of an algorithm and sometimes it will decrease the performance. We will use a pipeline to perform the steps: Scaling => PCA => GaussianNB.\n",
    "\n",
    "Interestingly, the performance of GaussianNB is better when the features are not scaled, so StandardScaler is omitted below.  We also use the features `nb_best_features` that we found before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def tune_nb_clf(f_list, scaling=True):\n",
    "    '''\n",
    "    This function tries to optimize GaussianNB using a pipeline and GridSearchCV by\n",
    "    applying the steps:  Scaling (or not) => PCA => GaussianNB\n",
    "    \n",
    "    Input:\n",
    "    f_list - a list of features to use for the algorithm \n",
    "    '''\n",
    "    data_array = featureFormat(new_data_dict, f_list, sort_keys=True)\n",
    "    labels, features = targetFeatureSplit(data_array)\n",
    "    labels, features = np.array(labels), np.array(features)\n",
    "    \n",
    "    # create a pipeline with scaling/no scaling, pca, and GaussianNB\n",
    "    scaler, pca, nb_clf = StandardScaler(), PCA(), GaussianNB()\n",
    "    steps = [('pca', pca), ('nb', nb_clf)]\n",
    "    if scaling:\n",
    "        steps = [('scaling', scaler)] + steps\n",
    "    pipe = Pipeline(steps)\n",
    "    \n",
    "    # hyperparameters and parameter grid for grid search\n",
    "    num_components = range(1, len(f_list))\n",
    "    whiten = [True, False]\n",
    "    priors = [(0.9,0.1), (0.87,0.13), (0.8,0.2), (0.7,0.3)]\n",
    "    \n",
    "    param_grid = dict(pca__n_components=num_components,\n",
    "                      pca__whiten=whiten,\n",
    "                      nb__priors=priors)\n",
    "    \n",
    "    # setup GridSearchCV with StratifiedShuffleSplit for cross validation\n",
    "    cv_sss = StratifiedShuffleSplit(n_splits=100, test_size = 0.3, random_state=42)\n",
    "    grid_search = GridSearchCV(pipe, param_grid, scoring='f1', n_jobs=-1, cv=cv_sss)\n",
    "    grid_search.fit(features, labels)\n",
    "\n",
    "    # the optimal model from GridSearchCV is\n",
    "    nb_clf = grid_search.best_estimator_\n",
    "    \n",
    "    return nb_clf, param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"nb_results\"></a>\n",
    "### 1b. Naive Bayes Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hyperparameter</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pca__n_components</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pca__whiten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nb__priors</td>\n",
       "      <td>(0.7, 0.3)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      hyperparameter       value\n",
       "0  pca__n_components           4\n",
       "1        pca__whiten        True\n",
       "2         nb__priors  (0.7, 0.3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.85686\tPrecision: 0.49893\tRecall: 0.46750\tF1: 0.48271\tF2: 0.47347\n",
      "Total predictions: 14000\tTrue positives:  935\tFalse positives:  939\n",
      "False negatives: 1065\tTrue negatives: 11061\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def display_model_results(estimator, param_grid, f_list):\n",
    "    '''\n",
    "    Display the results from tuning a machine learning classifier.  Shows the\n",
    "    optimal hyperparameters resulting from GridSearch and also tests the classifier\n",
    "    using the test_classfier() function.\n",
    "    \n",
    "    Inputs:\n",
    "    estimator - best estimator from a fitted GridSearchCV object run through a pipeline\n",
    "    param_grid - parameter grid used for the grid search\n",
    "    f_list - features to use for the algorithm\n",
    "    '''\n",
    "    \n",
    "    best_parameters = estimator.get_params()\n",
    "    tuples = []\n",
    "    for parameter in param_grid.keys():\n",
    "        tuples.append((parameter, best_parameters[parameter]))\n",
    "    \n",
    "    parameters_df = pd.DataFrame(tuples, columns=['hyperparameter', 'value'])\n",
    "    display(parameters_df)\n",
    "    \n",
    "    test_classifier(estimator, new_data_dict, f_list)\n",
    "    \n",
    "nb_clf, nb_grid = tune_nb_clf(nb_best_features, scaling=False)\n",
    "display_model_results(nb_clf, nb_grid, nb_best_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"dt\"></a>\n",
    "### 2. The Decision Tree Algorithm\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id=\"tuning_dt\"></a>\n",
    "### 2a. Tuning the Decision Tree\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def tune_dt_clf(f_list, scaling=True):\n",
    "    '''\n",
    "    '''\n",
    "    data_array = featureFormat(new_data_dict, f_list, sort_keys=True)\n",
    "    labels, features = targetFeatureSplit(data_array)\n",
    "    labels, features = np.array(labels), np.array(features)\n",
    "    \n",
    "    # pipeline\n",
    "    scaler, dt_clf = MinMaxScaler(), DecisionTreeClassifier()\n",
    "    steps = [('dt', dt_clf)]\n",
    "    if scaling:\n",
    "        steps = [('scaling', scaler)] + steps\n",
    "    pipe = Pipeline(steps)\n",
    "    \n",
    "    # hyperparameters and parameter grid for grid search\n",
    "    criterion = ['gini', 'entropy']\n",
    "    splitter = ['best', 'random']\n",
    "    max_depth = range(30, 80, 5)\n",
    "    min_samples_split = [2,3,4]\n",
    "    min_samples_leaf = [1,2,3]\n",
    "    class_weight = ['balanced']\n",
    "    \n",
    "    param_grid = dict(dt__criterion=criterion, dt__splitter=splitter,\n",
    "                      dt__max_depth=max_depth, dt__min_samples_split=min_samples_split,\n",
    "                      dt__min_samples_leaf=min_samples_leaf, dt__class_weight=class_weight)\n",
    "    \n",
    "    # setup GridSearchCV with StratifiedShuffleSplit for cross validation\n",
    "    cv_sss = StratifiedShuffleSplit(n_splits=100, test_size = 0.3, random_state=42)\n",
    "    grid_search = GridSearchCV(pipe, param_grid, scoring='f1', n_jobs=-1, cv=cv_sss)\n",
    "    grid_search.fit(features, labels)\n",
    "    \n",
    "    # the optimal model from GridSearchCV is\n",
    "    dt_clf = grid_search.best_estimator_\n",
    "    \n",
    "    return dt_clf, param_grid\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hyperparameter</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dt__criterion</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dt__splitter</td>\n",
       "      <td>best</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dt__max_depth</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dt__min_samples_split</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dt__min_samples_leaf</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dt__class_weight</td>\n",
       "      <td>balanced</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          hyperparameter     value\n",
       "0          dt__criterion      gini\n",
       "1           dt__splitter      best\n",
       "2          dt__max_depth        55\n",
       "3  dt__min_samples_split         3\n",
       "4   dt__min_samples_leaf         3\n",
       "5       dt__class_weight  balanced"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.82014\tPrecision: 0.41315\tRecall: 0.61600\tF1: 0.49458\tF2: 0.56092\n",
      "Total predictions: 14000\tTrue positives: 1232\tFalse positives: 1750\n",
      "False negatives:  768\tTrue negatives: 10250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_clf, dt_grid = tune_dt_clf(dt_best_features)\n",
    "display_model_results(dt_clf, dt_grid, dt_best_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
